<!doctype html>
<html lang="en-gb">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <title>Data Engineering // Agent Arachnids Anthology</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.133.0">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Paul Brown" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="/css/main.min.5b1fcc8902588589c4767187402a3c29f8b8d7a6fdef6d9f8f77045bb0d14fee.css" />
    

    
  


    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Data Engineering">
  <meta name="twitter:description" content="Storyplaces I was employed as a placement with my University. I was given a goal to present my analysis findings to a group of PhD students, and to help me with this my manager gave me a list of tasks that needed doing from the weekly level, with an individual list of goals for each week. I used primarily Python and more specifically Pandas for this project.
For the first week it was purely exploratory analysis, finding basic things out like how many users on any given day, how long did each user spend on average, etc.">

    <meta property="og:url" content="http://localhost:1313/university-projects/data-engineering/">
  <meta property="og:site_name" content="Agent Arachnids Anthology">
  <meta property="og:title" content="Data Engineering">
  <meta property="og:description" content="Storyplaces I was employed as a placement with my University. I was given a goal to present my analysis findings to a group of PhD students, and to help me with this my manager gave me a list of tasks that needed doing from the weekly level, with an individual list of goals for each week. I used primarily Python and more specifically Pandas for this project.
For the first week it was purely exploratory analysis, finding basic things out like how many users on any given day, how long did each user spend on average, etc.">
  <meta property="og:locale" content="en_gb">
  <meta property="og:type" content="article">
    <meta property="article:section" content="university-projects">
    <meta property="article:published_time" content="2024-09-05T11:46:29+01:00">
    <meta property="article:modified_time" content="2024-09-05T11:46:29+01:00">


  </head>
  <body>
    <header class="app-header">
      
      <span class="app-header-title">Agent Arachnids Anthology</span>
      <nav class="app-header-menu">
          <a class="app-header-menu-item" href="/personal-projects/">Personal Projects</a>
             - 
          
          <a class="app-header-menu-item" href="/professional-projects/">Professional Projects</a>
             - 
          
          <a class="app-header-menu-item" href="/tutorials/">Tutorials</a>
             - 
          
          <a class="app-header-menu-item" href="/university-projects/">University Projects</a>
      </nav>
      <p>Lead Developer of Spyderweb Studios, and Multiplayer Technical Designer</p>
      <div class="app-header-social">
        
          <a href="https://github.com/agentarachnid66" target="_blank" rel="noreferrer noopener me">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>Github Account</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg>
          </a>
        
          <a href="https://www.linkedin.com/in/paul-b-745268138/" target="_blank" rel="noreferrer noopener me">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-linkedin">
  <title>LinkedIn</title>
  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle>
</svg>
          </a>
        
          <a href="https://www.youtube.com/@agentarachnid2009" target="_blank" rel="noreferrer noopener me">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-youtube">
  <title>YouTube</title>
  <path d="M22.54 6.42a2.78 2.78 0 0 0-1.94-2C18.88 4 12 4 12 4s-6.88 0-8.6.46a2.78 2.78 0 0 0-1.94 2A29 29 0 0 0 1 11.75a29 29 0 0 0 .46 5.33A2.78 2.78 0 0 0 3.4 19c1.72.46 8.6.46 8.6.46s6.88 0 8.6-.46a2.78 2.78 0 0 0 1.94-2 29 29 0 0 0 .46-5.25 29 29 0 0 0-.46-5.33z"></path><polygon points="9.75 15.02 15.5 11.75 9.75 8.48 9.75 15.02"></polygon>
</svg>
          </a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Data Engineering</h1>
      <div class="post-meta">
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Sep 5, 2024
        </div>
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          3 min read
        </div>
      </div>
    </header>
    <div class="post-content">
      <h2 id="storyplaces">Storyplaces</h2>
<p>I was employed as a placement with my University. I was given a goal to present my analysis findings to a group of PhD students, and to help me with this my manager gave me a list of tasks that needed doing from the weekly level, with an individual list of goals for each week. I used primarily Python and more specifically Pandas for this project.</p>
<p>For the first week it was purely exploratory analysis, finding basic things out like how many users on any given day, how long did each user spend on average, etc.</p>
<p>The second week was focused on more in depth analysis, more specifically user classification. Firstly, I had to come up with an algorithm that would take in an individual&rsquo;s metrics, calculated by crossreferencing the analysis I did in the first week, and designate a classification.</p>
<p>The third week was centred around choice analysis and pattern recognition, like if 2 pages were far apart if that effected player&rsquo;s choice or if a certain path is popular and why? I created a graphical representation of the story, and using this I created a list of every possible path in the story in varying lengths between the distance between 2 nodes and from the top and bottom of the graph. Then converting these paths to a string that could be looked up in each player&rsquo;s path, I could easily get the frequency of each path.</p>
<p>The final week was preparing for the presentation, so I was creating visualisations for the data. I used R Studio &amp; Excel to create the geographical visualisations and Python for the other graphs.</p>
<h2 id="conference-paper">Conference Paper</h2>
<p>I was recommended to do some data engineering for another professor at Bournemouth University whilst I was in my final semester and the <strong><a href="https://www.researchgate.net/publication/376789395_Association_between_air_temperature_and_unintentional_drowning_risk_in_the_United_Kingdom_2012-2019_A_nationwide_case_crossover_study">paper</a></strong> was published. I was given a list of data files and was told that I had to find the coordinates of each incident in the file and the closest station associated with the station. This would essentially find which station is responsible for each drowning incident. The simplest way of determining the distance was using the Haversine Formula. This alone provided some interesting challenges as the data showed which stations were permanently closed down before the incident and some were still open but the incident happened outside of their normal operational hours, so my method getting around this was if one station was invalid, then it would recursively search for the next nearest one. It would do this until either a valid station is found or the search limit is reached, I set this to 10 by default. My final task was to add the Air Temperature and Rainfall metrics from the previous 14 days from the incident date to the data set and then export it.</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
